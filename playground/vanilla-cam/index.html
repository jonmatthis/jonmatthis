<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>WebCodec with Tauri</title>
  <style>
    body { display: flex; justify-content: center; align-items: center; height: 100vh; }
    canvas { border: 1px solid black; }
  </style>
</head>
<body>
<canvas id="outputCanvas"></canvas>
<script>
  async function setupCamera() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      const video = document.createElement('video');
      video.srcObject = stream;
      await video.play();
      
      // Once video starts playing, we can start drawing frames
      requestAnimationFrame(() => drawFrame(video));
    } catch (error) {
      console.error("Error accessing the camera", error);
    }
  }

  function drawFrame(video) {
    const canvas = document.getElementById('outputCanvas');
    const context = canvas.getContext('2d');
    
    // Adjust canvas size to video frame
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // This is where you'd replace the straightforward draw with WebCodec processing
    context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
    
    requestAnimationFrame(() => drawFrame(video)); // Continue drawing frames
  }
  
  setupCamera();
</script>
</body>
</html>
