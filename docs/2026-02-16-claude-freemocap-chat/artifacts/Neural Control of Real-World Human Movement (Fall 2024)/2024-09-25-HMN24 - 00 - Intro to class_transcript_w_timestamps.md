# Transcript: 2024-09-25-HMN2024 - 00 - Intro to class

## Source Information

- **Source Type:** YouTube Video
- **URL:** https://www.youtube.com/watch?v=cB6lWKBlEhE
- **Video ID:** `cB6lWKBlEhE`

---

**Total Duration:** 00:57:40

---

## Full Transcript

### Chunk 1 [00:00:00 - 00:10:00]

**[00:00:00]** So I'm now starting recording and starting to talk. So let's see, I gave myself notes.

**[00:00:12]** So this is a topics course, which, as I'm sure you all know, is typically. Topics courses are generally like they're off of the main schedule and there's some sort of other kind of topic that doesn't have like a proper class around it yet. And oftentimes those topics classes are taught to allow a professor, often a research professor like me, to kind of like highlight their own research in a way that sort of doesn't fit within the standard sort of like curricula of the university, sort of the standard STEM classes that you might typically take. And this. So like I said, I am technically a professor of biology, even though I don't really do much biology, because in this school there isn't like a dedicated neuroscience department.

**[00:01:07]** There's the BNS program, sub major minor. I can never remember what the status is on that, but my research would kind of fit in a number of possible different departments, departments, the most obvious ones being biology, because I study like, you know, the neural aspects of things and think about things such as neurons. Psychology would be, I think, a more an obvious fit because it's got the sensation and motor control kind of stuff. These days. I do a tremendous amount of software development in the sort of method building and research, sort of research tool development side of life, which is a relatively recent development.

**[00:01:52]** I've also worked sort of close to robotics, close to biomechanics, close to physical therapy. And the specific little sub domain of research that me as an individual carves out, it just doesn't really fit in any particular department. So part of the main structure of this course is to try to think about what is the, like, what are the inroads to the specific thing that I study, which I will talk about in a second. And the goal is to kind of give that sort of very broad survey of the various subtopics that sort of come together to make the specific domain that I study, which is human movement in natural environments. But more so than that, like my specific way of studying that, because you can study a particular topic in a bunch of different ways.

**[00:02:48]** And I have come from such a weird and wild background that it's sort of a interesting question of sort of how would you introduce someone to that field? It's not a field, it's just sort of a thing I've learned how to do over the course of a couple decades.

**[00:03:08]** So there is something that I kind of. It's something I have to say at the beginning of every class that I teach. And I have never found a super great way to say it, but I don't. I would not feel comfortable teaching a class to a room full of undergraduate people without acknowledging the moral elephant in the room, which is that none of this is okay. None of the general structure of academia education is morally defensible at almost any level.

**[00:03:48]** The amount to which you are being exploited financially to be in this room is absolutely indefensible and unconscionable. And there is truly nothing that I could ever do on this side of the podium that would ever be worth the financial burden that's being put on you by being here. You can do the math. If you want to calculate the number of people times the annual tuition, room and board, the number would come out to be something like 2 to 3 million dollars. If you wanted to be more conservative and only count credit hours, it would be somewhere around a quarter million dollars.

**[00:04:27]** It's indefensible. Absolutely not. Okay. And I have over the course of my four to five years, let's lose track time as being as a professor here, I have sort of had to find a lot of different ways of trying to handle the term is moral harm, which is the term that refers to the specific kind of sort of psychological trauma that occurs when you are forced to participate in an institution or a system that morally repugnant to you in some way. I'm here for a lot of the reasons that you are here, which is because I love learning, I love teaching, I love sort of scientific exploration.

**[00:05:07]** And the nature of society as it is is that to do that at the highest level, you sort of have to come to for legal reasons, I will say institutions like this one in order to participate in that. And it's the kind of thing that I didn't fully comprehend what that all meant until I became a professor. It's the kind of thing where like you're all students and you experience life as a student does, which is basically as a temporary person in an institution like this. When you have a set amount of time that you'll be here, you'll go through, you'll have the degree and then you'll leave. And so everything up to the point of becoming a professor type person has that kind of characteristic.

**[00:05:58]** You're an undergraduate, then you're a graduate student, then you're a postdoc. And then if you sort of out compete your peers, which is an insane concept, why are you trying to out compete your peers? You should work with your peers. To anyways, we'll get on to that. But all up until that point there is this sort of temporary nature to it.

**[00:06:18]** And I think in retrospect there felt like it was a kind of. It felt more. I felt like I was struggling against the system to try to succeed in that context. And then I happened to become a professor in the summer of 2019. So I had about a year of like boy, I sure did make it.

**[00:06:42]** And this is probably fine. And then summer of 2020 rolled around. Covid happened and with all of the various ways that that affected the world at large and me in particular, I basically just lost all faith in the academic and scientific systems in that summer and sort of had a whole crisis of conscience and tried to. Was trying to find ways of basically restructuring my life and my effort and sort of, you know, I've got. I had 35 and change years at that point of not 35 directly, but like close to 20 years of effort at that point to make it to this point.

**[00:07:20]** This is a position of non zero social power. And there is kind of this general idea of like don't give up power if you can use it to the benefit of your own moral beliefs or whatever. And it was a hard and challenging thing to think about and just to like try to sort of come. You know, what oftentimes happens when you work within institutions, which we are all forced to do, is there's a conflation between the values that you hold and the institutions that are sort of the vehicles for those values. And when you lose faith in an institution, which I highly recommend, just never trust institutions, trust people, don't trust institutions.

**[00:08:08]** There was a whole thing of trying to figure out what I was actually here for, what my actual goals and morals and values actually are. And a lot of things come out of that. Probably stuff that I still should not say on camera. But the general idea was a shift of focus from the doing the traditional modes of research and education, which pretty much to this day still involves do research for publications, apply for grants, produce students that will try to climb the same ladder. You are on understanding entirely that that's to get tenure.

**[00:08:54]** You're supposed to produce like, you know, more than two people who are also trying to get tenures at other school, which is sort of the definition of a Ponzi scheme. And that was sort of the effort. It's oftentimes when you're working in these types of systems that we tend to live in, which are competition based hierarchies predicated on assumptions of false scarcity. The game that you play is sort of, you're asked to compete with the people who are sort of at your same level in the hierarchy in order to please the people who are above you in the hierarchy, most of whom have been in that position for longer, sort of a gerontocracy type of thing. And I realized that a lot of the effort that I was putting in, almost like a very big percentage of the effort I was putting into the world, was made in the service of the people who were above me on the hierarchy and trying to do the things that they wanted me to do so that I could outperform my peers and be allowed to stay in the warm, happy signing tower.

---

### Chunk 2 [00:09:45 - 00:19:45]

**[00:09:45]** Was made in the service of the people who were above me on the hierarchy and trying to do the things that they wanted me to do so that I could outperform my peers and be allowed to stay in the warm, happy, shining tower at the top of the hill that we are all currently in. And so one of the big changes that I sort of brain shifts that happened was deciding to just stop doing that and to just stop caring or considering what I was being asked to do by people above me in the hierarchy and start asking instead what I could do to support people who were at or below me in that same hierarchy, which is largely y' all types.

**[00:10:32]** From a practical perspective, what that turned out to be was a. So in that time of sort of doing research, I sort of like, I've got all these papers, we'll talk about them. And with that sort of crisis of conscience, there was this question like, well, I don't. So universities are probably evil, Journals are definitely evil. But I do love the research, I do love the teaching.

**[00:11:00]** So what do you do if you don't want to, you know, do the dumb work of publishing a bunch of papers to try to make the powers that be happy to please the gatekeeping dinosaurs above you? What do you do with your time? And it was around that time, sort of through other modes. I mean, I had basically, I have a big Fancy Lab at Richard 453 which will be. Y' all will be touring with Aaron, not me next week because I'll be out of town.

**[00:11:32]** And when Covid hit, so I showed up, I had all these plans for the research I was going to do in the big fancy lab. And they were doing the construction. And the construction wrapped up around January and I was sort of gearing up to start the research cycle. And then quarantine hit got sort of sent home and had to sort of for a while just kind of flailed around trying to figure out, like, what am I going to do with my time? What are we going to do with our time?

**[00:12:03]** And at that time, I wound up basically there were a couple things happening in my lab at that point, Most of which were related to work in like the big fancy mocap lab. And then there was one little side project that involved this computer vision based method for doing motion capture with like cheapo webcams and free software. And so when Covid hit, I basically we shifted effort towards working entirely on that because that was a project that we could work on sort of remotely with ease and sort of kind of figure that out. And so that was like March or whatever. And then as we sort of got into the summer and that project started to sort of of like pick up some steam and I started losing faith in the system and all that kind of stuff, I found myself kind of coming across software such as Blender, which we're going to talk about.

**[00:13:04]** Blender. Blender is a free open source. Sorry, got that sort of stuck in my head. It's a big free open source 3D animation software. It's been around for some decades.

**[00:13:14]** It's a large scale, wide scale thing and it has been. It is 100% free, 100% open source and built over the course of decades by thousands of people across the world and given away freely as a gift, freely given for anyone to use and benefit from. And I kind of had this moment of realization that that was actually the thing that I wanted to be doing. The open source community is what the scientific community pretends to be like. We pretend as scientists that we are doing that, that we're working in this big sort of global collaborative endeavor, but it's not.

**[00:13:53]** But practically speaking, you're just not really able to do it. So most of the research that gets done really shouldn't be done. It's not good research. It's just smart research. It's strategically the right move to get the publication, to get the grants, to get the job, to get the tenure.

**[00:14:09]** And it never often will serve. Like, I'm not saying that all scientists are idiots and that all research is garbage, although the percentage is higher than you wish it was, but the nature of the institutions that sort of house it and the realities of like the hyper competitive structures of society that we've sort of grown for ourselves are that you're not really able to do it in a way that really benefits anybody outside of the club. And, and when you see scientists, sort of traditional scientists doing outreach, it's often this kind of just like side thought, like, I'm going to go to a high school, show them how cool it is to be super highly educated and then just leave and then hope that they're inspired enough to follow in your path out compete their peers, and then maybe they someday can get into that shining tower at the top of the hill.

**[00:15:00]** It just didn't seem right to me. So long story short, such as it is, all of that kind of culminated into a sort of, or not culminated, but sort of over a long course of time that became basically. Did I break it? This guy. This is computer.

**[00:15:24]** There you go. So this is Duke freemocap.org so this is a software that I've been working on with Aaron for about five years. It's called FreeMap. It's a free open source markerless motion capture system. And it's basically been the thing that has soaked up the energy that would have been spent publishing papers and trying to make people happy.

**[00:15:57]** I instead spent building this tool to do full body motion capture with cheapo garbage webcams and free software. And it's been going quite well and we're going to talk plenty more about that. It's on GitHub, free mocap there. There's a Discord server with looks like like pushing 2,500 members in it got about, I think last I checked approaching 5,000 unique users in like 115 countries, which is all quite good. And the focus of the project and the software is to, instead of taking my particular skill set and expertise which I have sort of accumulated over the course of decades now, using mostly taxpayer funding to pay my salaries and my paychecks and rather than trying to use that to just publish super esoteric papers that will only be beneficial to other super esoteric people, the goal was to try to package that same, use that expertise to build a tool that sort of meets a general need of society at large and then sort of try to start building that tool as both the thing that the world wants, also the tool that I want to do my research and ideally trying to use that as a mechanism for building bridges and sort of pulling people in.

**[00:17:28]** So a lot of the, I would say at this point still the majority of users of this software are animators, often young 3D, animation artists, video game designers, things like that. And also a bunch of students and grad students and biomechanics, clinical, whatever this, that and the other, a lot of dancers and musicians and things like that. And they are using this software for their own purposes. That's sort of part of it. I don't want to tell you what you should care about.

**[00:18:02]** I'd rather just give you useful tools and let you do what you want to do with it. But because I, with help Global, we design this thing based up from my perspective. I am also trying to sort of surreptitiously make this as a tool that is also kind of an educational platform in its own right. Something that will, it doesn't teach you directly, it's not giving you like lessons and quizzes, but the nature of the tool is to try to teach you how it works and to try to kind of basically the idea is to give you kind of a greased rail into the densest part of the forest and then shine enough lights that you can sort of navigate yourself around there. A lot of the education, the general structure of education that y' all tend to receive is sort of this like, let's start with the basics.

**[00:18:57]** Let's start with the simple, boring stuff that frankly is not particularly motivating on its own. But because trust me, trust me, it's going to lead somewhere so cool. And if you can only hang on and out compete your peers for long enough, then you'll be able to see all the cool, fun stuff. And there is actually a reaction that I have had more than once when I talked about the software to people, which is, you should be careful not to make it too easy to use, otherwise the students won't understand what's going on in there. And it's like insane to me to think that, because I would much.

**[00:19:34]** Because the reality is that in the natural world, in the real world, your first reaction upon encountering something is often going to.

---

### Chunk 3 [00:19:30 - 00:29:30]

**[00:19:30]** Insane to me to think that, because I would much. Because the reality is that in the natural world, in the real world, your first reaction upon encountering something is often going to be confusion. Like when you first come across some strange artifact, that's the least you were ever going to understand it. And you will wind up, if you're lucky, slowly kind of backing your way into a level of understanding. And so, rather than trying to basically hold your hands on a very specific path with an intended outcome of the thing that I'm trying to show you, I am instead going to be trying to show you a broad landscape that is, you are frankly.

**[00:20:24]** That is frankly going to be pretty over your head for the most part and then allow you and give you the tools that you need to kind of gravitate towards the parts of that landscape that are the most motivating to you as individuals and then allow you to kind of give you the tools that you need to kind of like back your way into a place of understanding and basically working your way from like the advanced stuff in the center of the woods back to the beginner shit that we really should have started with so that you can basically ground yourself from that position. But the reality is that because it's such a broad landscape, you're all going to sort of find different parts of it and you're going to need different parts of that beginner, basic stuff, and we'll kind of sort of gravitate in that direction.

**[00:21:17]** So little bit of. Yeah, let me see where I'm at with this.

**[00:21:30]** There's more.

**[00:21:33]** This is still context, right? So that's the general gist of the life that I live. And there's a little bit of. I mean, the class is obviously overlapping with that general thing because I'm the one standing up here and you guys are over there. Specifically within this class, there's another player, which is that the story I was telling you about sort of like the loss of faith and the finding of the free open source thing and sort of the reshaping around this software and educational blah, blah, blah.

**[00:22:15]** All of that is basically started in roughly summer of 2020, and it's kind of been progressing since there. I've taught a couple of classes, sort of win that vibe. I see a couple of familiar faces, possibly from inquiries in some cases. Has anyone been in a class with me before? No.

**[00:22:37]** Who are you people?

**[00:22:42]** Well, yeah, I've worked on trying to like teaching this type of stuff and trying this like broad landscape thing and trying to incorporate as much of these sort of like, deep tech tools as I could. And then I guess it was, what was it like two years ago now, April, a year and a half ago, there was a certain technological event which occurred and you heard about it. And the hype cycle has sort of come and gone to the point where you're probably annoyed about it at this point. But the thing in question is artificial intelligence. My background, my first degree is in philosophy.

**[00:23:26]** I got a degree in philosophy, a focus on philosophy of mind and philosophy of science. There's going to be a lot of that specific, the philosophy of science in this course. And from there I got a PhD in cognitive science, which is effectively AI studies these days. And my particular domain within cognitive science, which is another one of this, like, mishmash, like sort of comedically broad fields, was on the, like, the biological side, like psychology, neuroscience kinds of stuff. But I also did a lot of work with robotics.

**[00:23:59]** I did a lot of sort of. I learned a lot about AI, machine learning and sort of theories of language and all that stuff. And when GPT 3.5 came out, like, I've been following the various language models since, you know, roughly 2008.

**[00:24:20]** And when 3.5 came out, I saw it and I was like, oh, wow, this is. This is getting really good. This is really a very. They've really been working over there. And then when GPT4 came out, it was just like, okay, there is now a shift has occurred and it is now important to take note of it.

**[00:24:42]** So I contacted my. I remember very clearly. I was, you know, I can't remember exactly the timing of it, but at some point I have a friend named John Linstadt who will probably come up later, who's a friend from graduate school. And he was much more on that AI side of things. He was a director of the cognitive science program at SUNY Oswego for a while.

**[00:25:03]** And I sort of. We got onto the Discord chat or whatever and he says, john, we need to discuss the situation. And we both immediately knew that the situation was that AI exists and it is not a.

**[00:25:23]** It's not like you don't have to worry about it as coming to life and biting you. That's not a thing. And pretty much anything you're going to see from almost any source is going to be missing the point to some degree or another. It's one of the nice things about being an expert is, I guess basically looks like, oh, yeah, I'll have it wrong.

**[00:25:44]** And it's not endgame. And there's still a lot to happen. But it is a major shift in technology that 100% is going to reshape our society in a lot of predictable and unpredictable ways over the course of the next five to 10 to 20 years.

**[00:26:04]** And not necessarily for the better. It is as most technologies, it has come from the techno capitalist corpo hegemony that is the source of so much of the sort of problems and harm in our society. And in much the same way that they have sort of, you know, I'd say caused significant damage to our social infrastructure over the past 20 some odd years, they are going to attempt to continue to do that and they're going to attempt to use the. Anytime there's a new technology that comes around, the techno capitalists or just the capital, the corporal capitalists basically try to rush to the new domain and start building moats around it so that they can sequester it and then use their access to that thing as a way to exploit the world at large. That is the true core of capitalism is to exploit disparities between yourself and others to extract resources from them.

**[00:27:06]** And so a lot of, and I think at this point a lot of that's probably become somewhat apparent and there's probably at least a percentage of you who are sort of like feel like AI ick because it is so overwhelmingly tied to the corpo techno capitalist infrastructure. But there is another angle to that and I think that it can be very difficult to recognize the. It's very difficult I think, especially when you're coming at something from like a non expert position to discern a separation between the core technology that exists and the sort of implementation of that technology. Like it's hard for us to see things like GPT4 on OpenAI as anything other than just like another arm of Microsoft. It's hard to see whatever the hell it is that Google is trying to do as anything other than just like another way to steal your data and another way to shape the world around sucking $20 a month out of you for sort of a bunch of basic functionalities that you are going to eventually require for your daily life.

**[00:28:24]** But I think that it's really important to, I think that this particular technology is different because unlike a lot of other tools and other like so things like computers and phones and things like that, like these are also world shaping technologies and they did shape the world and you were sort of a part of it. And I think a lot of you all are the both beneficiary and harmed individuals from what happened over the past 20 years when the entire world basically shifted towards everything that we do in our daily lives is going to be pushed and pulled through through apps that are made by corporations that do not have your best interest at heart.

**[00:29:13]** And there was sort of an inherent. That disparity between the ability to make these applications, to build these types of technologies was one that was pretty easy to exploit because, you know, I can't make this. I can't make a chip, I can't. I mean, I guess I can build an app, but it's not going to be the same thing. If you would.

---

### Chunk 4 [00:29:15 - 00:39:14]

**[00:29:15]** Between the ability to make these applications, to build these types of technologies was one that was pretty easy to exploit because, you know, I can't make this. I can't make a chip. I can't. I mean, I guess I can build an app, but it's not going to be the same thing that you would get from a Google or a Facebook. And so they get to use that, and they get to use the fact that this is now an essential technology.

**[00:29:37]** You know, we find these technologies and we sort of reshape our society to them.

**[00:29:43]** And there's sort of this limitation there. AI, I think, is different because it is fundamentally. It's like they're trying to build moats around the Mote Blaster 9000. Like, it is a tool that will teach you how it works and it will show you everything there is to know about itself. And they're trying to create, corral it and control it.

**[00:30:08]** And sort of in the same way that they used that they sort of. That you sort of were used to, and it's kind of just not working in the way that they would expect. We'll talk about that in detail. I don't want to go too deep down this rabbit hole because that is definitely something I like to do. But I'm mostly kind of saying that just to sort of comment on the tech ick that I think is a fair response to the world that we live in.

**[00:30:39]** Because I do think that sort of AI used properly is something that has the ability to be a transformatively liberative tool and one that has the potential to make every single human person that learns how to use it and learns how to wield it a more powerful and capable version of yourself.

**[00:31:06]** It's not an oracle that will solve all of your problems, which is how it's often trying to be pushed on you.

**[00:31:14]** It's not something that's automatically going to make the world better, but it is an unbelievably powerful tool that if you learn how to use it, whatever it is that you are trying to do in your life, if it involves the generation, sort of understanding, manipulation of text on a screen, AI can help with that. It's not automatically. It won't build all your life for you, but it is an unbelievably powerful tool with a very shallow initial learning curve and as far as I can tell, an un unlimited maximum possibility.

**[00:31:55]** So that will lead us Discord. Don't do that.

**[00:32:15]** So I live a lot of my life on Discord, which I didn't. I appreciate the Software for what it is, but I also kind of hate it for what it is. And when GPT4 came online like I guess spring of 2023 or something like that, one of the first things I did is I built a bot out of it and started using it to teach a class. And it was a summer class. And then I taught another version of this class last fall and then I taught a class Capstone in the spring.

**[00:32:55]** Didn't go so well. And then now this is the fourth iteration of using AI Empowered Discord Bot as a way to try to teach and provide yaw types with the ability to sort of explore a topic that is sort of broad and vast and complex.

**[00:33:22]** So we're going to talk about details of that sort of ad nauseam at some point. But the basic idea is that this. So here's the server, which is sort of structured roughly around the topic of the class. And here is this bot named Skelly Bot that lives in the server. So the, this is Skelly, it's like the logo of mascot of Free Mocap.

**[00:33:49]** And so Free Mocap, the software has a bunch of little small parts and they're all named like Skelly something. So like the camera part is called skellycam, the bot part is called Skelly Bot. If you're curious about it, you can click on Skelly Bot and then this GitHub link here will take you to the source code for it. And I think the most important part of this is this phrase right here.

**[00:34:13]** This bot helped me build this bot. I could not have made this thing without this thing.

**[00:34:23]** The skills and sort of like technical aspects of building a thing like this. I wasn't trained in computer science. I managed to hack and slash my way through grad school and sort of like building the. In order to like. And I was able to build the basics of the Free mocap software because that is my domain of expertise.

**[00:34:42]** This is not. I have under. I mean I have like an understanding, theoretical understanding of AI, but building a tool like this was beyond me. But the thing about these AI is you just say, hey, could you help me with this thing? And it's like, yeah, absolutely, no problem, 100%.

**[00:34:57]** And it will give you an answer which is mostly right. Often, not always, but often. And if you learn how to navigate that and use that and sort of like surf the various ways that it is right and wrong and learn the kind of things that it like, oh, this is the problem that AI is going to, it's not going to Be able to do that? Oh, it's absolutely going to be able to do that. If you can learn how to navigate that space and use these tools, it will power level you through spaces that you could have hacked and flashed your way through over time, that you could have sat down with a real human primate expert who would explain it to you piece by piece.

**[00:35:37]** Or you can just learn how to ask the machine and the machine will sort of help you do these things.

**[00:35:45]** How exactly that happens is complex. There's not like a quick answer. It's like most complex tools. The learning process is a little bit of instruction with a lot of just like try it, see how it goes. And part of the structure of this course is to sort of give you the opportunity to do that within the landscape of the neural control of real world human movement.

**[00:36:10]** Doopa doopa doo. So specifically now coming to like AI within an educational context, if you. So when I am up here as like a career research scientist with some decades of experience in this very sort of rather niched out field, like I'm not. So like a lot of times if you're like a standard specialist, you're like in the niche of a niche of a niche of a niche of a field. So you're sort of like a very, very specific person.

**[00:36:45]** My particular version of that is I'm within a niche of a niche of a niche of a niche. So it's sort of not that deep down, but it's like it's sort of a breadth versus depth kind of thing, which can be harder to do. It's not necessarily harder to do. It takes the same amount of time. But it can be harder to teach because I can't assume that you all have gone through like, if I was like an advanced, you know, epigenetics immunology expert, I can say, okay, have you all done like, you know, intro bio, cell bio, like, you know, whatever.

**[00:37:19]** Da da da da. All the expertise is that you would need to get to this sort of level of specificity and depth with this kind of very broad area. I can't assume that it's possible that some of you have some of the pre reqs, but none of you are going to have all of them because I've checked and pretty much one of the, like, there are roughly one person in the world that has all of my same background because I just, I bounce around so much that the specificity that you get to is just kind of, you become a uniqueness when you start overlapping enough skill sets pretty quickly, which is just also just generally good career advice. It is way easier to be unique by just combining a bunch of different things and then eventually you sort of see that all the you overlap enough Venn diagrams and you look at sort of who is shared amongst all those Venn diagrams. It's like oh wait this is actually just me.

**[00:38:20]** Which is way sort of easier and more fun to do than to try to sort of out compete everybody that sort of is in the same sort of space and domain. But you know, follow your heart. Oh shit, y' all found your way in. Good job.

**[00:38:42]** So the general vibe of AI within this class will be that this so who here has used GPT at all like prompted the a little bit talk to it you say hi, it says hi back. You ask it a question it says something back.

**[00:39:07]** The low the base level introduction there is prompting AI large language models in particular.

---

### Chunk 5 [00:39:00 - 00:49:00]

**[00:39:00]** A little bit, talk to it, you say hi, it says hi back. You ask it a question, it says something back.

**[00:39:08]** The base level introduction there is prompting AI. Large language models in particular are at their core language calculators. In the same way that you would sort of punch a bunch of numbers into a calculator, push go, and it gives you another number. Language models do roughly the same thing. You push a bunch of words into their context window, push go, and it looks at its unbelievable sort of data set and provides a statistically most likely answer that is the expected and desired outcome of the input to the output.

**[00:39:53]** Yeah, so and I'm going to say this, even though this is a little bit off, off of that topic, but the main thing that happened, I think the main is like there was like an empirical event that happened, like an interesting empirical event that happened arguably with something like GPT4 versus like the earlier incarnations of it, which was when I was in, when I was an undergraduate and studying philosophy of language, there were sort of this, this question of does language require some sort of like native, native genetic, like neurophysiological architecture to be able to happen? Like, is there something special about the human evolutionary lineage that allows us to do language? Or the question was, is it possible that you could just sort of extract language from a large enough data set and some clever statistics? And when I was in undergrad at like, what was that, 2006 or so, it was kind of like, it's hard to say, who knows. And I remember at the time there was like, you know, like undergraduate, right.

**[00:41:09]** So there were like, there were some people there who had been like, the professor was sort of more attuned to like the, you know, what was going on in the field. It's like, yeah, those like the, the statistical people are making some interesting progress in that space, but they're still not doing anything that resembles proper language. And what happened for me, as from my sort of perspective with GPT4, was that question was answered very definitively. And the answer was yes, it is in fact possible to extract language from a large enough data set and some clever statistics without ever giving it explicit rules of grammar or explicit concepts of words and anything like that. And I consider that to be an empirical discovery and the sort of, from a psychological, like a psych testing experiment.

**[00:41:57]** It's sort of like, how do you know that that happened? It's like, well, I'm a human and I talk to it and I'm like, oh yeah, that's interesting. Like I have a conversation with the machine. And it's like, you are definitely. The machine is definitely doing language.

**[00:42:09]** And that language is derived truly purely from the statistics of the data set, which in this case represents, like, every stitch of text that was written on the Internet since 1985, and some clever statistics, which is basically, in this case, transformer models, which just search for that if you're interested in it. So, yeah, so that's a bit of an aside, but I think that that is the thing that. That was the situation that my friend John wanted to talk about. It's like, oh, shit. We just.

**[00:42:48]** The world may not really. May not realize it. Like, this is not how. I do not hear this being discussed in this way in sort of the highest. In broad channels.

**[00:42:59]** But the question to the answer to that question has been empirically discovered. And yeah, you actually can extract language from statistics. And we also now have. And so another thing that happened is we now have a secondary example, for the first time in history, a secondary example of a thing that can carry out a conversation. It's not a good conversation in many cases.

**[00:43:24]** It's certainly not a human. It's not really. It's definitely not conscious, but it's a cognitive agent. It does language, math in its head. And before you hear people saying, like, oh, it's not really doing language because it's just like using a statistic to predict the best output.

**[00:43:44]** And it's like, y', all, I got some real bad news for you about what you're doing when you're doing language. So I guess that's.

**[00:43:57]** Yeah, anyways, that's part of the landscape of what's going on here. And so there is also a part of, again, like, the ethical obligations that I feel like I have as the person standing on the chairs are facing this way, which is that there is this new technology. It has emerged onto the landscape. I don't really see it being understood or utilized at large.

**[00:44:30]** And I am sort of like, fairly uniquely suited to teach it, use it, that type of thing. And so I think that this is one of the most useful things I can do for you, is introduce you to this technology, this tool, show you how it works, and teach you sort of how you can utilize it in your own cases. Even if you wind up not using it in the future, it will affect your life from the outside.

**[00:44:55]** Like this technology, like all technologies, they can and will be used against you. So you should understand it to the extent that you can utilize it, to the extent that it helps you become a more effective version of yourself and My job and hope is to allow you and help you do that.

**[00:45:19]** So. Right. So in the specific way that I want to I have used it and will continue to use it is to prompt the bot, the term is prompting to basically try to get the bot to act like, like effectively like a simulation of myself and a simulation of my expertise. Obviously the very best education that y' all could get from this class is if I sat down with each one of you individually, asked you what your interests were, helped you work through things, answered your questions, gave you some answers and did that individually for you on call 24 7. Every answer.

**[00:46:11]** But I unfortunately am a limited piece of meat and that is not within my capacity. So instead I can make this bot which is absolutely not as good as having a sit down conversation with me. But it's not bad and it will allow you to. Basically there's this question of like how good are these things? Like, and I'm sure you get all sorts of sort of like the responses that I've seen to AI from a lot of the educational landscape is very defensive and it's sort of like don't use it for teaching, don't use it for, don't use it for your.

**[00:46:53]** Don't use it for it's don't cheat, don't basically don't cheat, don't whatever, write your papers, blah blah blah. It's not in this like it gets it wrong. It's got these hallucinations, blah blah blah, like all these things sort of like try to get you not to use it.

**[00:47:11]** And it's true that it will get most things, it gets things wrong at some level and it has absolutely no idea when it's saying something wrong. There's this thing called the grounding problem which is just a philosophy of AI is just like a thing.

**[00:47:31]** It will tell you the exactly right answer in the exactly wrong answer with the exact same level of confidence in itself. And so there is a certain. That's one of the things you have to learn is when to recognize when it's getting things right and wrong. However, there is another aspect of it which is that its ability to be right about things like its is pretty much entirely contingent on its data set. If the question that you're asking is present in the data set, it will tend to get it right.

**[00:48:10]** It's kind of like a Google search. Like you can search for pages that exist. If you search for something that doesn't exist, well, these days it'll just get you a bunch of garbage that's close by. And I guess a good analogy would be imagining searching for something that doesn't exist. And instead of showing you a bunch of stuff that's not the thing you want, the answer was I'm just going to take the top three things that you don't want and then tell you that this is the answer to your question.

**[00:48:34]** So it's not gaslighting you because it truly believes the things that it said, but it is an aspect of the thing that it does not know whether it's right or wrong.

**[00:48:50]** However, because the nature of this class is a lot of basically like mid level expertise in a bunch of different domains, the.

---

### Chunk 6 [00:48:45 - 00:57:40]

**[00:48:45]** It does not know whether it's right or wrong.

**[00:48:49]** However, because the nature of this class is a lot of like, basically like mid level expertise in a bunch of different domains, most of the questions that y' all will have about these fields and subfields are things that exist in textbooks. If it's a question, if the answer to the question exists in a textbook somewhere, it tends to nail it. And this is, I'm saying this on the basis of having like taught classes with this. If you ask simple questions about like, you know, what's the oculomotor system? Like what's the cerebellum up to?

**[00:49:24]** What's superior colliculus? Like how does a muscle work? Like, what's the evolution? Like what's up with the elbow? What's that deal?

**[00:49:29]** What's a motor unit? What's a Golgi tendon organ? It nails all those questions because those are all not. If the question has been asked and answered at least 10,000 times since 1985 on the Internet, it will tend to get it right. And so the interesting space that you are now in.

**[00:49:53]** So for me, because I've been alive for long enough to have expertise, you all don't, not because you're dumb, just because it takes longer than that to, to develop expertise.

**[00:50:07]** I've been studying what I study for as long as many of you all have been alive. And I'm still, I'm starting to get to the point where it's like, oh, most of what I know now is I have a good enough sense of the landscape that I know the difference between the things that I know, the things that we know as a species and the things that we don't quite know as a species. So I'm in a very good position to be able to talk to the bot and sort of to push it into areas that I know, like the really fiddly answers to it. And I get to see it kind of go wrong and go off the rails and sort of like start making stuff up and start guessing and making frankly the kinds of guesses that I see like non experts make. Like when you, if you're.

**[00:50:50]** I don't want to like talk down about non research professors, but like a teaching professor who is not in like the specific domain of research that you're talking about is like. Or not even teaching textbooks. Textbooks are mostly wrong. That's kind of one of the secrets of if it has been around for long enough to be written down in a textbook, it's probably wrong at some level. It's at the very least, a cartoonized version of the real thing, which is always going to be more complex than up there.

**[00:51:21]** It's always going to be less stable than you are often led to believe. One of the many bad.

**[00:51:32]** Yeah. One of the many themes of this class will be acting under uncertainty. And one of the recurrent themes there is that we know a lot more and a lot less than you're often tend to taught. I think that the nature of undergraduate education is like, there's tests, there's quizzes, there's papers, there's quiz grades. There's this sort of like, certification system that we go through.

**[00:51:55]** It's like, yes, you understand organic chemistry. And the nature of that is that things are often presented to you as if they are right or wrong, true or false. Like, what's the answer to this question? Oh, it's B. That's not really how the world works.

**[00:52:13]** Like, they're like, questions can be like, get into the philosophy of science aspect of that later. But the world's a lot murkier than we would like for it to be. And that is true of science. It's true of every field.

**[00:52:28]** And I lost my point. But yeah, anyways, so the idea will be that within this space and that the structure of this class is going to be encouraging you to navigate this area. And then rather, and what AI will allow us to do versus an earlier era of life is it will allow each of you to navigate a much more uniquely. You'll basically all be able to choose your own trajectory through this space. Because the thing to be, like, if I'm up here giving a lecture about, you know, biomechanics or neuromechanics or something like that, I have to kind of think about, like, are they going to be able to follow any of this?

**[00:53:16]** Is this any of this going to. Going to land? And like, if I can't. So I have to, like, limit the density of the things I say to try to make sure that, like, at least a percentage of you can sort of follow the plot.

**[00:53:29]** But is it 125 of the class over? Yeah, but one thing I get to do with AI and I'm going to give it a shot at the end. I think we should have time when I should start talking about the content of the class.

**[00:53:47]** But one of the things that this allows me to do is to be much, much, much denser in the information that I present to you, because I'm going to talk about things that are going to be over your head. And it's going to come real fast and you're not going to follow all of it, I can guarantee you already. But that's going to be okay because I'm going to record it and then once I record it, I'm going to scrape the audio, put it into the AI as like an outline of topics, put that in one of the channels, and then one of the assignments will be go ask the bot about whichever. Which part of this was the most interesting to you? Which part of this was the most confusing to you?

**[00:54:30]** Which part of this do you wish I had said more about? Which part of this did I say something about? But you didn't follow it at all. And so my goal will be to say all the things that need to be said, to say in a way that you. That you can follow, because you're all smart people.

**[00:54:49]** And your job is going to be to basically stand in front of the fire hose and try not to let your brain turn off entirely and try to just let it wash over you. And to notice when you have something that sort of like wakes up, like when I mentioned some this or that or some topic over here, some topic over there, to notice what those things are. And then in your own time and with your machines or whatever, explore those topics and sort of seek out deeper depth and knowledge about those things. And you can do that 24 hours a day, seven days a week. This thing will answer every question you have at any point forever.

**[00:55:33]** It will never get tired. It will never get annoyed. There are no dumb questions. It is always down and learning how to navigate that, I think. So basically it will stop the traditional problems of student teaching, which is like to get.

**[00:55:53]** It will break you out of broke of fail states and it will help you jump over hurdles and sort of that. That's basically like, I don't know what to do. I have no. I'm. I'm so lost.

**[00:56:03]** I don't even know which way to go. Just ask the machine and it will give you help.

**[00:56:09]** Okay, so from Here we have 35 minutes left. Calm down.

**[00:56:25]** Trying to think of what I want to do specifically.

**[00:56:33]** I'm going to do this kind of in the.

**[00:56:46]** Okay, I'm going to try to make sure I want to get you all. I'm choosing between. With the possibility of running out of time, getting you sort of set up with the technical aspects of this versus like dumping a bunch of content on you traditional first day of class stuff. I'm going to focus on the technical setup and there's a whole rest of the semester left. No syllabus survives first contact with the classroom.

**[00:57:11]** So if the schedule shifts, I'm honestly okay with that.

**[00:57:17]** So, yeah.

**[00:57:27]** So something like 20 of you have made it here already.

**[00:57:36]** So, to start, let's start with the canvas course.

---
