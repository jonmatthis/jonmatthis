OMB No. 0925-0001 and 0925-0002 (Rev. 10/15 Approved Through 10/31/2018)

# **BIOGRAPHICAL SKETCH**

Provide the following information for the Senior/key personnel and other significant contributors.  
Follow this format for each person. **DO NOT EXCEED FIVE PAGES.**

NAME: Jonathan Samir Matthis	

eRA COMMONS USER NAME (credential, e.g., agency login): jonmatthis

POSITION TITLE: Assistant Professor (Northeastern University) / President (FreeMoCap Foundation)

EDUCATION/TRAINING *(Begin with baccalaureate or other initial professional education, such as nursing, include postdoctoral training and residency training if applicable. Add/delete rows as necessary.)*

| INSTITUTION AND LOCATION | DEGREE *(if applicable)*  | Completion Date MM/YYYY  | FIELD OF STUDY  |
| :---: | ----- | ----- | ----- |
| University of Maryland – Baltimore County (UMBC) | BA | May 2007 | Philosophy |
| Rensselaer Polytechnic Institute | MS | Dec 2011 | Cognitive Science |
| Rensselaer Polytechnic Institute | PhD | May 2014 | Cognitive Science |
| University of Texas at Austin | Post-Doc | Jun 2019 | Neuroscience |

1. # **Personal Statement**

My primary research goal is to understand the guiding principles and neural bases the stability and grace of human movement. In particular, I seek to understand the way that the human central nervous system integrates information from the sensory systems in order to generate stable and precise actions to achieve goals and move through the world. In my early graduate years, I worked with my advisor Brett Fajen in the Perception and Action lab at RPI to study the way that humans use visual information to select actions when moving through a complex environment. For my dissertation work, I developed a novel experimental apparatus that used an Augmented Reality groundplane in order to study the visual control of foot placement when walking over complex terrain (The work described in Aims 1 and 2 is an advancement of this methodology and line of research).  A core features of my research is to use the basic biomechanics of bipedal gait as the starting point to the study of the visual control of foot placement. In my post-doctoral work, I began my study of the visual control of walking in natural environments, which offers many new insights that could not be gained from studying locomotion in a constrained laboratory setting. By leveraging emerging technologies such as mobile eye trackers and IMU based motion capture, I was able to accurately record walkers’ 3D gaze and full-body kinematics as they walked over unconstrained real-world terrain. As Northeastern, I will continue to use new technology to record quantified measurements of human performance in natural settings, as well as performing controlled lab-based experiments to test hypotheses derived from the real-world observational studies. In recent years, I have shifted focus away from the publication of esoteric papers towards the development of free open source software that serves direct public needs. To this end, I have formed the FreeMoCap Foundation (an IRS certified 501c3 public charity) and developed the FreeMoCap software, with the goal of providing research quality markerless motion capture to everyone in the world for free. 

**Highlighted Research Products**

1. **FreeMoCap Markerless Motion capture software** (hosted at `freemocap/freemocap` on the GitHub code repository website)  
2. Matthis, J. S., Muller, K. S., Bonnen, K. L., & Hayhoe, M. M. (2022). Retinal optic flow during natural locomotion. *PLoS computational biology*, *18*(2), e1009575. PMID:.1009575  
     
3.  **Matthis, J.S**., Yates, J.L., Hayhoe, M.M. (2018). Gaze and the visual control of foot placement when walking over real-world rough terrain. *Current Biology. 28\. 1224-1233.* PMID:29657116

4. **Matthis, J.S**., Barton, S.L, Fajen, B.R. (2017). The critical control phase for the visual control of walking over complex terrain. *Proceedings of the National Academy of Sciences*. 114(32). 6720-6729. PMID: 28739912  
   

A complete list of my publications can be found here \- [https://pubmed.ncbi.nlm.nih.gov/?term=Matthis+JS\&cauthor\_id=29657116](https://pubmed.ncbi.nlm.nih.gov/?term=Matthis+JS&cauthor_id=29657116)

#  **B.	Positions and Honors**

**Position since last degree**

2022 – Present – President – FreeMoCap Foundation, Inc (501c3)

2019 – Present – Assistant Professor – Department of Biology – Northeastern University

2014 – 2019 – Post-Doctoral researcher – Center for Perceptual Systems – University of Texas at Austin

**Awards and Honors**

* Selected for *Post-Doctoral Trainee* position by CPS NEI NIH Training Grant steering committee (Fall 2014 – Spring 2016\)

* Rensselaer Humanities, Arts & Social Sciences Fellowship providing full support for 24 months (RPI, Fall 2010 – Summer 2012\)

* Travel Grant to attend 2012 meeting of Dynamic Walking group (May 2012\)

* Travel Grant to attend 2011 meeting of Dynamic Walking group (August 2011\)

* Travel Grant to attend Centre for Vision Research Conference (June 2009\)

* Glenn M. Trawinski Student Leadership Award (UMBC, Spring 2007\)

* Best in Conference Award (SIUE Undergraduate Philosophy Conference, November 2006\)

* Graduated *Magna Cum Laude* (UMBC, May 2007\)

* Graduated with Departmental Honors (UMBC, May 2007\)

# **C.	Contribution to Science** 

# **1\. Advancing and disseminating technology related to the measurement, study, and analysis of real-world human behavior.** In my work developing the FreeMoCap Project (and its associated Foundation), I have utilized my unique scientific capabilities and background to develop a global and growing community of users around a software designed to record research quality full body kinematic data for free. The Free Motion Capture (FreeMoCap) software has been used by over 5000 users in 115 countries/ 

**a.** **FreeMoCap Markerless Motion capture software** (hosted at `freemocap/freemocap` on the GitHub code repository website)

# **2\. Gaze and the control of foot placement during locomotion over real-world rough terrain.** My post-doctoral work examines the gaze allocation strategies that support locomotion over real world rough terrain environments. This research advances the field by adding insight into the control of locomotion in natural environments to existing approaches that rely on simplified lab-based environments. Early results suggest that this project will substantially alter our current understanding of the visual control of human locomotion.

**a.** Matthis, J. S., Muller, K. S., Bonnen, K. L., & Hayhoe, M. M. (2022). Retinal optic flow during natural locomotion. *PLoS computational biology*, *18*(2), e1009575. PMID:.1009575

b. **Matthis, J.S**., Yates, J.L., Hayhoe, M.M. (2018). Gaze and the visual control of foot placement when walking over real-world rough terrain. *Current Biology. 28\. 1224-1233.* PMID:29657116

**c.** Muller, .KM, **Matthis, J.S**., Hayhoe, M.M., (In Preparation). Retinal optic flow during natural locomotion. 

**d.** Hayhoe, M.M., **Matthis, J.S.,** (2018) Control of gaze in natural environments: effects of rewards costs uncertainty and memory in target selection. *Royal Society Interface Focus. (8),* PMID: 29951189

**3\. The role of biomechanics in the visual control of foot placement.** My doctoral work examined the way that the biomechanics and physical dynamics of bipedal gait shape the visual control streatgies that are used to guide foot placement during locomotion over complex terrain. Drawing on the theoretical framework afforded by the passive dynamic perspective on human gait, I discovered that there is a critical phase in the human gait cycle for the visual control of foot placement. These results have resulted in several publications in high impact journals (see below), and have been cited in publications from researchers in a diverse variety of fields, such as perceptual psychophysics, clinical and theoretical biomechanics, robotic control systems, and comparative biology. 

**a. Matthis, J.S**., Barton, S.L, Fajen, B.R. (2017). The critical control phase for the visual control of walking over complex terrain. *Proceedings of the National Academy of Sciences*. 114(32). 6720-6729. PMID: 28739912

**b. Matthis, J. S**. & Fajen, B. R. (2013). Humans exploit the biomechanics of bipedal gait during visually guided walking over complex terrain. *Proceedings of the Royal Society B: Biological Sciences*, 280(1762). 1-9. PMID: 23658204  

**c. Matthis, J. S**. & Fajen, B. R. (2014). Visual control of foot placement when walking over complex terrain.  *Journal of Experimental Psychology: Human Perception and Performance.* 40(1). 106-15. PMID: 23750964

**d.** Barton, S. L., **Matthis, J. S.**, & Fajen, B. R. (2019). Control strategies for rapid, visually guided adjustments of the foot during continuous walking. *Experimental Brain Research*, PMID: 30976822

**4\.  Visual Control Strategies for foot placement in robotic bipedal locomotion.** In addition to my contributions to the field of sensorimotor neuroscience and psychology, my research also has direct applications to the field of legged robotics. Current approaches to the control of legged robots rely on extremely fast feedback loops, but are generally lacking in feed forward “vision-like” control. My work identifying the visual control strategies that humans use to guide foot placement in rough terrain has been inspired the development of novel control systems for bipedal robots. My collaboration with robotics researchers has been fostered through invited talks (a-c, below) and in a joint poster at the 2016 Dynamic Walking conference (d, below). 

**a. Matthis, J.S**., (2019). *“Retinal optic flow and the visual control of locomotion”* Invited talk presented to the Boston Dynamics Robotics Lab.

**b. Matthis, J.S.,** (2016). *“The coupling of gaze and gait when walking over real-world rough terrain.”* Invited talk presented to the Robotics Institute at Oregon State University.

**c. Matthis, J.S.,** (2015). *“The critical phase for visual control of walking over complex terrain.”* Invited talk presented to the humanoid robotic locomotion research group at the Boston Dynamics Robotics Lab.

**d. Matthis, J.S.** (2013). *“Visual control of precise foot placement when walking over complex terrain.”* Invited talk presented at the Robotics Institute of Carnegie Mellon University.

**5\.  Visual and Non-visual contributions to estimations of locomotor capabilities.** In my early graduate career, I worked on a research project that examined the role of visual and non-visual information about self-motion to actor’s estimations of their own locomotor capabilities. This project extended upon the “flow parsing” hypothesis to the identification of independently moving objects during self-motion by showing that non-visual information about self-motion contributes to actors perception about the movement of objects in their environment.  

**a.** Fajen, B. R., & **Matthis, J. S.** (2011). Direct perception of action-scaled affordances: The shrinking gap problem. *Journal of Experimental Psychology: Human Perception and Performance*, 37(5), 1442-1457. PMID: 21500936

**b.** Fajen, B. R., & **Matthis, J. S.** (2013). Visual and non-visual contributions to the perception of object motion during self-motion. *PLoS ONE* 8(2), 1-12. PMID: 23408983

**c.** Fajen, B. R., Parade, M. S., & **Matthis, J. S.** (2013). Humans perceive object motion in world coordinates during obstacle avoidance. *Journal of Vision*, 13(8), 1-13. PMID: 23887048

